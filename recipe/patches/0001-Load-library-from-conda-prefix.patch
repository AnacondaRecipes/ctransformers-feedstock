From 767f146422f55dd61919dc301debe16453412f30 Mon Sep 17 00:00:00 2001
From: Jean-Christophe Morin <jcmorin@anaconda.com>
Date: Fri, 20 Oct 2023 20:07:32 -0400
Subject: [PATCH] Load library from conda prefix

---
 ctransformers/lib.py | 76 ++------------------------------------------
 ctransformers/llm.py |  5 ---
 setup.py             |  1 -
 3 files changed, 2 insertions(+), 80 deletions(-)

diff --git a/ctransformers/lib.py b/ctransformers/lib.py
index 0b85d5a..6ffaeae 100644
--- a/ctransformers/lib.py
+++ b/ctransformers/lib.py
@@ -1,3 +1,4 @@
+import os
 import platform
 from ctypes import CDLL
 from typing import List, Optional
@@ -7,44 +8,7 @@ from .logger import logger
 
 
 def find_library(path: Optional[str] = None, gpu: bool = False) -> str:
-    lib_directory = Path(__file__).parent.resolve() / "lib"
-
-    if path:
-        subdirs = [d.name for d in lib_directory.iterdir() if d.is_dir()]
-        if path not in subdirs:
-            return path
-
     system = platform.system()
-    metal = gpu and system == "Darwin"
-    cuda = gpu and not metal
-    if not path:
-        if (lib_directory / "local").is_dir():
-            path = "local"
-        elif cuda:
-            path = "cuda"
-        elif metal:
-            path = "metal"
-        elif platform.processor() == "arm":
-            # Apple silicon doesn't support AVX/AVX2.
-            path = "basic" if system == "Darwin" else ""
-        else:
-            from cpuinfo import get_cpu_info
-
-            try:
-                flags = get_cpu_info()["flags"]
-            except:
-                logger.warning(
-                    "Unable to detect CPU features. "
-                    "Please report at https://github.com/marella/ctransformers/issues"
-                )
-                flags = []
-
-            if "avx2" in flags:
-                path = "avx2"
-            elif "avx" in flags and "f16c" in flags:
-                path = "avx"
-            else:
-                path = "basic"
 
     name = "ctransformers"
     if system == "Linux":
@@ -56,44 +20,8 @@ def find_library(path: Optional[str] = None, gpu: bool = False) -> str:
     else:
         name = ""
 
-    path = lib_directory / path / name
-    if not path.is_file():
-        if cuda:
-            env = "CT_CUBLAS=1 "
-        elif metal:
-            env = "CT_METAL=1 "
-        else:
-            env = ""
-        raise OSError(
-            "Precompiled binaries are not available for the current platform. "
-            "Please reinstall from source using:\n\n"
-            "  pip uninstall ctransformers --yes\n"
-            f"  {env}pip install ctransformers --no-binary ctransformers\n\n"
-        )
-    return str(path)
+    return os.path.join(os.environ["CONDA_PREFIX"], "lib", name)
 
 
 def load_cuda() -> bool:
-    try:
-        import nvidia
-    except ImportError:
-        return False
-    path = Path(nvidia.__path__[0])
-    system = platform.system()
-    if system == "Windows":
-        libs = [
-            path / "cuda_runtime" / "bin" / "cudart64_12.dll",
-            path / "cublas" / "bin" / "cublas64_12.dll",
-        ]
-    else:
-        libs = [
-            path / "cuda_runtime" / "lib" / "libcudart.so.12",
-            path / "cublas" / "lib" / "libcublas.so.12",
-        ]
-    for lib in libs:
-        if not lib.is_file():
-            return False
-    libs = [str(lib.resolve()) for lib in libs]
-    for lib in libs:
-        CDLL(lib)
     return True
diff --git a/ctransformers/llm.py b/ctransformers/llm.py
index 90cdfe2..516b93f 100644
--- a/ctransformers/llm.py
+++ b/ctransformers/llm.py
@@ -115,11 +115,6 @@ def get(*values):
 
 
 def load_library(path: Optional[str] = None, gpu: bool = False) -> Any:
-    # https://docs.python.org/3.8/whatsnew/3.8.html#bpo-36085-whatsnew
-    # https://github.com/abetlen/llama-cpp-python/pull/225
-    if hasattr(os, "add_dll_directory") and "CUDA_PATH" in os.environ:
-        os.add_dll_directory(os.path.join(os.environ["CUDA_PATH"], "bin"))
-
     path = find_library(path, gpu=gpu)
     if "cuda" in path:
         load_cuda()
diff --git a/setup.py b/setup.py
index 46fcc47..bc3a657 100644
--- a/setup.py
+++ b/setup.py
@@ -30,7 +30,6 @@ setup(
     url="https://github.com/marella/{}".format(name),
     license="MIT",
     packages=[name, "ctransformers.gptq"],
-    package_data={name: ["lib/*/*.so", "lib/*/*.dll", "lib/*/*.dylib"]},
     install_requires=[
         "huggingface-hub",
         "py-cpuinfo>=9.0.0,<10.0.0",
-- 
2.42.0

